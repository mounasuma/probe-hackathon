{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":92221,"databundleVersionId":10979176,"sourceType":"competition"},{"sourceId":10642298,"sourceType":"datasetVersion","datasetId":6589342}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\n# Paths to images and masks\nimage_dir = '/kaggle/input/probe-d/png_images/IMAGES/'\nmask_dir = '/kaggle/input/probe-d/png_masks/MASKS/'\n\n# Get list of image files\nimages = sorted([f for f in os.listdir(image_dir) if f.endswith('.png')])\nmasks = sorted([f for f in os.listdir(mask_dir) if f.endswith('.png')])\n\n\n# Split the data into training and testing (80%-20%)\ntrain_images, test_images, train_masks, test_masks = train_test_split(\n    images, masks, test_size=0.2, random_state=33\n)\n\n# Save split data into CSV (this will be useful for tracking splits)\ntrain_df = pd.DataFrame({\n    'image': train_images,\n    'mask': train_masks\n})\n\ntest_df = pd.DataFrame({\n    'image': test_images,\n    'mask': test_masks\n})\n\n# Save dataframes for later use\ntrain_df.to_csv('/kaggle/working/train_split.csv', index=False)\ntest_df.to_csv('/kaggle/working/test_split.csv', index=False)\n\n# Check the first few entries of the training set\ntrain_df.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T09:48:52.476422Z","iopub.execute_input":"2025-02-03T09:48:52.476810Z","iopub.status.idle":"2025-02-03T09:48:53.070059Z","shell.execute_reply.started":"2025-02-03T09:48:52.476781Z","shell.execute_reply":"2025-02-03T09:48:53.068936Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"          image          mask\n0  img_0867.png  seg_0867.png\n1  img_0910.png  seg_0910.png\n2  img_0641.png  seg_0641.png\n3  img_0583.png  seg_0583.png\n4  img_0517.png  seg_0517.png","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>img_0867.png</td>\n      <td>seg_0867.png</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>img_0910.png</td>\n      <td>seg_0910.png</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>img_0641.png</td>\n      <td>seg_0641.png</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>img_0583.png</td>\n      <td>seg_0583.png</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>img_0517.png</td>\n      <td>seg_0517.png</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing import image\nimport cv2\n\ndef load_image(image_path):\n    img = cv2.imread(image_path, cv2.IMREAD_COLOR)  # Use OpenCV to read images\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n    img = cv2.resize(img, (825, 550))  # Ensure consistent size\n    return img\n\ndef load_mask(mask_path):\n    mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # Load as grayscale\n    mask = cv2.resize(mask, (825, 550))  # Resize to match image size\n    return mask\n\n# Create a dataset loader\ndef create_dataset(image_paths, mask_paths):\n    image_data = [load_image(os.path.join(image_dir, image)) for image in image_paths]\n    mask_data = [load_mask(os.path.join(mask_dir, mask)) for mask in mask_paths]\n    return np.array(image_data), np.array(mask_data)\n\n# Example usage:\ntrain_images_data, train_masks_data = create_dataset(train_images, train_masks)\ntest_images_data, test_masks_data = create_dataset(test_images, test_masks)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T09:48:56.935735Z","iopub.execute_input":"2025-02-03T09:48:56.936096Z","iopub.status.idle":"2025-02-03T09:49:31.925332Z","shell.execute_reply.started":"2025-02-03T09:48:56.936069Z","shell.execute_reply":"2025-02-03T09:49:31.924082Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T09:50:32.780438Z","iopub.execute_input":"2025-02-03T09:50:32.780893Z","iopub.status.idle":"2025-02-03T09:50:32.792108Z","shell.execute_reply.started":"2025-02-03T09:50:32.780863Z","shell.execute_reply":"2025-02-03T09:50:32.790854Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\ndef create_model(input_shape):\n    model = models.Sequential([\n        layers.InputLayer(input_shape=input_shape),\n        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n        layers.MaxPooling2D(),\n        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n        layers.MaxPooling2D(),\n        layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n        layers.UpSampling2D(),\n        layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n        layers.UpSampling2D(),\n        layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n        layers.Conv2D(59, (1, 1), activation='softmax', padding='same'),\n        layers.ZeroPadding2D(padding=((1, 1), (1, 0)))   # Adjust padding to match target size (825x550)\n    ])\n    return model\n\n# Example model creation\ninput_shape = (550, 825, 3)  # Height, Width, Channels (RGB)\nmodel = create_model(input_shape)\ninitial_learning_rate = 0.001  # You can experiment with this value\noptimizer = Adam(learning_rate=initial_learning_rate)\n\n# Use ReduceLROnPlateau to reduce learning rate when validation loss plateaus\nlr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n\n# Compile the model\nmodel.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n# Display model summary\nmodel.summary()\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T09:50:35.358706Z","iopub.execute_input":"2025-02-03T09:50:35.359095Z","iopub.status.idle":"2025-02-03T09:50:35.537335Z","shell.execute_reply.started":"2025-02-03T09:50:35.359067Z","shell.execute_reply":"2025-02-03T09:50:35.536243Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/input_layer.py:26: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m, \u001b[38;5;34m825\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m275\u001b[0m, \u001b[38;5;34m412\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m275\u001b[0m, \u001b[38;5;34m412\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m137\u001b[0m, \u001b[38;5;34m206\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m137\u001b[0m, \u001b[38;5;34m206\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m73,856\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m274\u001b[0m, \u001b[38;5;34m412\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m274\u001b[0m, \u001b[38;5;34m412\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m73,792\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ up_sampling2d_1 (\u001b[38;5;33mUpSampling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m548\u001b[0m, \u001b[38;5;34m824\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m548\u001b[0m, \u001b[38;5;34m824\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │          \u001b[38;5;34m18,464\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m548\u001b[0m, \u001b[38;5;34m824\u001b[0m, \u001b[38;5;34m59\u001b[0m)        │           \u001b[38;5;34m1,947\u001b[0m │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ zero_padding2d (\u001b[38;5;33mZeroPadding2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m550\u001b[0m, \u001b[38;5;34m825\u001b[0m, \u001b[38;5;34m59\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">825</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">275</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">275</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">137</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">206</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">274</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">274</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">412</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ up_sampling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">548</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">824</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">548</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">824</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">548</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">824</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,947</span> │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ zero_padding2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ZeroPadding2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">550</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">825</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">59</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m187,451\u001b[0m (732.23 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,451</span> (732.23 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m187,451\u001b[0m (732.23 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">187,451</span> (732.23 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"history = model.fit(train_images_data, train_masks_data, batch_size=4, epochs=10, validation_split=0.2, verbose=1)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T09:50:40.668320Z","iopub.execute_input":"2025-02-03T09:50:40.668762Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2479s\u001b[0m 15s/step - accuracy: 0.7340 - loss: 2.2266 - val_accuracy: 0.7668 - val_loss: 1.2319\nEpoch 2/10\n\u001b[1m 42/160\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28:09\u001b[0m 14s/step - accuracy: 0.7669 - loss: 1.3145","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# Evaluate the model on the test data\ntest_loss, test_accuracy = model.evaluate(test_images_data, test_masks_data, verbose=1)\n\n# Print the test loss and accuracy\nprint(f'Test Loss: {test_loss}')\nprint(f'Test Accuracy: {test_accuracy}')\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T09:45:45.158954Z","iopub.execute_input":"2025-02-03T09:45:45.159272Z","iopub.status.idle":"2025-02-03T09:46:12.545130Z","shell.execute_reply.started":"2025-02-03T09:45:45.159244Z","shell.execute_reply":"2025-02-03T09:46:12.544312Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1s/step - accuracy: 0.7802 - loss: 1.0060 \nTest Loss: 1.014285922050476\nTest Accuracy: 0.7786061763763428\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import save_img\n\n# Make predictions on the test data\npredictions = model.predict(test_images_data)\n\n# Post-process predictions: Convert one-hot predictions to class labels\npredicted_masks = np.argmax(predictions, axis=-1)  # Convert the output to class labels\n\n# Save the predicted masks as PNG files\nfor i, mask in enumerate(predicted_masks):\n    # Save each mask with the corresponding image name (make sure the names match the input images)\n    output_filename = f'pred_mask_{i+1}.png'  # Modify the filename as needed\n    save_img(output_filename, mask)  # Save mask as PNG\n    print(f'Saved mask {output_filename}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T09:46:28.540088Z","iopub.execute_input":"2025-02-03T09:46:28.540390Z","iopub.status.idle":"2025-02-03T09:46:39.969155Z","shell.execute_reply.started":"2025-02-03T09:46:28.540367Z","shell.execute_reply":"2025-02-03T09:46:39.967892Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m1/7\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 498ms/step","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-a5d64a00e1b2>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Make predictions on the test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Post-process predictions: Convert one-hot predictions to class labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-13-a5d64a00e1b2>\", line 6, in <cell line: 6>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 512, in predict\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 208, in one_step_on_data_distributed\n\nOut of memory while trying to allocate 5548753208 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_data_distributed_54788]"],"ename":"ResourceExhaustedError","evalue":"Graph execution error:\n\nDetected at node StatefulPartitionedCall defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-13-a5d64a00e1b2>\", line 6, in <cell line: 6>\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 512, in predict\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\", line 208, in one_step_on_data_distributed\n\nOut of memory while trying to allocate 5548753208 bytes.\n\t [[{{node StatefulPartitionedCall}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_one_step_on_data_distributed_54788]","output_type":"error"}],"execution_count":13},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.backend import clear_session\n\nclear_session()  # Clear any cached memory from previous models\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-03T09:48:21.927229Z","iopub.execute_input":"2025-02-03T09:48:21.927472Z","iopub.status.idle":"2025-02-03T09:48:39.293631Z","shell.execute_reply.started":"2025-02-03T09:48:21.927448Z","shell.execute_reply":"2025-02-03T09:48:39.292410Z"}},"outputs":[],"execution_count":1}]}